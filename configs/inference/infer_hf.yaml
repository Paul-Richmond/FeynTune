model_name: meta-llama/Meta-Llama-3.1-8B

generation_cfg:
  max_new_tokens: 1024
  min_new_tokens: 1
  temperature: 0.7
  do_sample: true

repo_name: LLMsForHepth/infer_hep_th
