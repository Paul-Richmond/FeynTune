num_train_epochs: 100
evaluation_strategy: "no"
log_level: info
logging_steps: 1
max_grad_norm: 1.0
per_device_train_batch_size: 5
per_device_eval_batch_size: 5
output_dir: hf
report_to: wandb
run_name: ???
push_to_hub: true
hub_model_id: LLMsForHepth/${training.run_name}
hub_private_repo: true