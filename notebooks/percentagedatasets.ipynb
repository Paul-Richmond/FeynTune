{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new percentage datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    hf_token = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "    huggingface_hub.login(token=hf_token)\n",
    "except:\n",
    "    huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get base datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_th = load_dataset('LLMsForHepth/hep-th_primary')\n",
    "ds_hep_ph_gr_qc = load_dataset('LLMsForHepth/hep-ph_gr-qc_primary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = {k: ds_hep_th[k].num_rows for k in ds_hep_th.keys()}\n",
    "sizes_15 = {k: int(0.15 * v) for k, v in sizes.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 70% and 85% of hep-th dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_85 = DatasetDict({split: ds_hep_th[split].select(range(sizes[split] - sizes_15[split])) for split in sizes.keys()})\n",
    "ds_hep_70 = DatasetDict({split: ds_hep_th[split].select(range(sizes[split] - 2 * sizes_15[split])) for split in sizes.keys()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 15% each of the hep-ph and gr-qc categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter datasets so we have only 'hep-ph' or 'gr-qc' catagories appearing\n",
    "ds_hep_ph = ds_hep_ph_gr_qc.filter(lambda x: x['categories'][:6] == 'hep-ph')\n",
    "ds_gr_qc = ds_hep_ph_gr_qc.filter(lambda x: x['categories'][:5] == 'gr-qc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_ph_15 = DatasetDict({split: ds_hep_ph[split].select(range(sizes_15[split])) for split in sizes.keys()})\n",
    "ds_gr_qc_15 = DatasetDict({split: ds_gr_qc[split].select(range(sizes_15[split])) for split in sizes.keys()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hep_th_85_gr_qc_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_th_85_gr_qc_15 = DatasetDict()\n",
    "names = ['train', 'test', 'validation']\n",
    "\n",
    "for name in names:\n",
    "    ds_hep_th_85_gr_qc_15[name] = concatenate_datasets([ds_hep_85[name], ds_gr_qc_15[name]])\n",
    "\n",
    "# randomly shuffle the concatenated datasets\n",
    "ds_hep_th_85_gr_qc_15 = ds_hep_th_85_gr_qc_15.shuffle(seed=42)\n",
    "ds_hep_th_85_gr_qc_15 = ds_hep_th_85_gr_qc_15.flatten_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datasets have same number of rows\n",
    "for split in ds_hep_th.keys():\n",
    "    assert ds_hep_th_85_gr_qc_15[split].num_rows == ds_hep_th[split].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_th_85_gr_qc_15.push_to_hub('LLMsForHepth/hep-th_85_gr-qc_15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hep_th_85_hep_ph_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_th_85_hep_ph_15 = DatasetDict()\n",
    "names = ['train', 'test', 'validation']\n",
    "\n",
    "for name in names:\n",
    "    ds_hep_th_85_hep_ph_15[name] = concatenate_datasets([ds_hep_85[name], ds_hep_ph_15[name]])\n",
    "\n",
    "# randomly shuffle the concatenated datasets\n",
    "ds_hep_th_85_hep_ph_15 = ds_hep_th_85_hep_ph_15.shuffle(seed=42)\n",
    "ds_hep_th_85_hep_ph_15 = ds_hep_th_85_hep_ph_15.flatten_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datasets have same number of rows\n",
    "for split in ds_hep_th.keys():\n",
    "    assert ds_hep_th_85_hep_ph_15[split].num_rows == ds_hep_th[split].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_th_85_hep_ph_15.push_to_hub('LLMsForHepth/hep-th_85_hep-ph_15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hep_th_70_gr_qc_15_hep_ph_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_th_70_gr_qc_15_hep_ph_15 = DatasetDict()\n",
    "names = ['train', 'test', 'validation']\n",
    "\n",
    "for name in names:\n",
    "    ds_hep_th_70_gr_qc_15_hep_ph_15[name] = concatenate_datasets([ds_hep_70[name], ds_gr_qc_15[name], ds_hep_ph_15[name]])\n",
    "\n",
    "# randomly shuffle the concatenated datasets\n",
    "ds_hep_th_70_gr_qc_15_hep_ph_15 = ds_hep_th_70_gr_qc_15_hep_ph_15.shuffle(seed=42)\n",
    "ds_hep_th_70_gr_qc_15_hep_ph_15 = ds_hep_th_70_gr_qc_15_hep_ph_15.flatten_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datasets have same number of rows\n",
    "for split in ds_hep_th.keys():\n",
    "    assert ds_hep_th_70_gr_qc_15_hep_ph_15[split].num_rows == ds_hep_th[split].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hep_th_70_gr_qc_15_hep_ph_15.push_to_hub('LLMsForHepth/hep-th_70_gr-qc_15_hep-ph_15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_hub.logout()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llmsforhepth",
   "language": "python",
   "name": "llmsforhepth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
