{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tables generated running `src/inference.py` from wandb\n",
    "\n",
    "This was originally a notebook on Kaggle, can't promise it works on Colab due to different virtual environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mp-richmond\u001b[0m (\u001b[33mllms-for-hepth\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wandb run path can be found on the wandb website as follows\n",
    "<center> <img  src=\"./run_path.png\" width=\"800\" />   <center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.18.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/paul/Desktop/GitHub repositories/hepthLlama/wandb/run-20240912_090123-ltjalefm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/llms-for-hepth/huggingface/runs/ltjalefm' target=\"_blank\">test_llama_3.1_batch48</a></strong> to <a href='https://wandb.ai/llms-for-hepth/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llms-for-hepth/huggingface' target=\"_blank\">https://wandb.ai/llms-for-hepth/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llms-for-hepth/huggingface/runs/ltjalefm' target=\"_blank\">https://wandb.ai/llms-for-hepth/huggingface/runs/ltjalefm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_runpath = 'llms-for-hepth/huggingface/ltjalefm'\n",
    "entity, project, run_id = wandb_runpath.split('/')\n",
    "run = wandb.init(entity=entity, project=project, id=run_id, resume=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"latest\"\n",
    "\n",
    "inference_name = f\"{entity}/{project}/run-{run_id}-inference:{version}\"\n",
    "gen_cfg_name = f\"{entity}/{project}/run-{run_id}-inference_gen_cfg:{version}\"\n",
    "\n",
    "# there may be a 3rd table \n",
    "scores_name = f\"{entity}/{project}/run-{run_id}-scores_table:{version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "df = run.use_artifact(inference_name, type='run_table').get(\"inference\").get_dataframe()\n",
    "df2 = run.use_artifact(gen_cfg_name, type='run_table').get(\"inference_gen_cfg\").get_dataframe()\n",
    "\n",
    "# if there is a 3rd table\n",
    "df3 = run.use_artifact(scores_name, type='run_table').get(\"scores_table\").get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/test_loss</td><td>2.0414</td></tr><tr><td>eval/test_mean_batch_perplexity</td><td>8.37392</td></tr><tr><td>eval/test_runtime</td><td>1255.2342</td></tr><tr><td>eval/test_samples_per_second</td><td>12.607</td></tr><tr><td>eval/test_steps_per_second</td><td>0.789</td></tr><tr><td>eval/train_loss</td><td>1.69284</td></tr><tr><td>eval/train_mean_batch_perplexity</td><td>5.87006</td></tr><tr><td>eval/train_runtime</td><td>5808.5565</td></tr><tr><td>eval/train_samples_per_second</td><td>12.713</td></tr><tr><td>eval/train_steps_per_second</td><td>0.795</td></tr><tr><td>total_flos</td><td>3496190116566270000</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>13848</td></tr><tr><td>train/grad_norm</td><td>1.75302</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.7157</td></tr><tr><td>train_loss</td><td>1.95654</td></tr><tr><td>train_runtime</td><td>115692.5013</td></tr><tr><td>train_samples_per_second</td><td>1.915</td></tr><tr><td>train_steps_per_second</td><td>0.12</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_llama_3.1_batch48</strong> at: <a href='https://wandb.ai/llms-for-hepth/huggingface/runs/ltjalefm' target=\"_blank\">https://wandb.ai/llms-for-hepth/huggingface/runs/ltjalefm</a><br/> View project at: <a href='https://wandb.ai/llms-for-hepth/huggingface' target=\"_blank\">https://wandb.ai/llms-for-hepth/huggingface</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240912_090123-ltjalefm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can now access the results as Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15825.000000\n",
       "mean         0.377511\n",
       "std          0.185452\n",
       "min         -0.136492\n",
       "25%          0.246984\n",
       "50%          0.393081\n",
       "75%          0.514890\n",
       "max          1.000000\n",
       "Name: SemScore, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['SemScore'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llmsforhepth",
   "language": "python",
   "name": "llmsforhepth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
